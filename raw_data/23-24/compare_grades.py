#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¯”å¯¹PDFå’ŒWordæ–‡æ¡£ä¸­çš„å­¦å·å’Œæ™ºè‚²æˆç»©
"""

import sys
import pandas as pd
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

try:
    import pdfplumber
except ImportError:
    print("è¯·å®‰è£…pdfplumber: pip install pdfplumber")
    sys.exit(1)

try:
    from docx import Document
except ImportError:
    print("è¯·å®‰è£…python-docx: pip install python-docx")
    sys.exit(1)

def extract_pdf_data(pdf_path):
    """ä»PDFæ–‡ä»¶æå–å­¦å·å’Œæ™ºè‚²æˆç»©"""
    print(f"æ­£åœ¨è¯»å–PDFæ–‡ä»¶: {pdf_path}")
    
    data = []
    with pdfplumber.open(pdf_path) as pdf:
        for page_num, page in enumerate(pdf.pages):
            print(f"å¤„ç†PDFç¬¬{page_num + 1}é¡µ")
            
            # å°è¯•æå–è¡¨æ ¼
            tables = page.extract_tables()
            if tables:
                for table in tables:
                    for row in table:
                        if row and len(row) >= 4:  # è‡³å°‘éœ€è¦4åˆ—
                            # è·³è¿‡è¡¨å¤´è¡Œ
                            if row[0] and str(row[0]).strip() and not str(row[0]).strip().startswith(('åºå·', 'æ’å', 'å§“å')):
                                student_id = str(row[0]).strip()
                                # ç¬¬å››åˆ—æ˜¯æ™ºè‚²æˆç»©
                                if len(row) > 3:
                                    grade = str(row[3]).strip() if row[3] else ""
                                    data.append({
                                        'å­¦å·': student_id,
                                        'æ™ºè‚²æˆç»©': grade,
                                        'é¡µé¢': page_num + 1
                                    })
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°è¡¨æ ¼ï¼Œå°è¯•æ–‡æœ¬æå–
            if not tables:
                text = page.extract_text()
                if text:
                    lines = text.split('\n')
                    for line in lines:
                        # ç®€å•çš„æ­£åˆ™åŒ¹é…å­¦å·æ¨¡å¼ (é€šå¸¸æ˜¯æ•°å­—)
                        import re
                        parts = re.split(r'\s+', line.strip())
                        if len(parts) >= 4 and parts[0].isdigit():
                            data.append({
                                'å­¦å·': parts[0],
                                'æ™ºè‚²æˆç»©': parts[3],
                                'é¡µé¢': page_num + 1
                            })
    
    print(f"ä»PDFæå–äº† {len(data)} æ¡è®°å½•")
    return data

def extract_word_data(docx_path):
    """ä»Wordæ–‡æ¡£æå–å­¦å·å’Œæ™ºè‚²æˆç»©"""
    print(f"æ­£åœ¨è¯»å–Wordæ–‡æ¡£: {docx_path}")
    
    data = []
    doc = Document(docx_path)
    
    # ä»è¡¨æ ¼ä¸­æå–æ•°æ®
    for table_idx, table in enumerate(doc.tables):
        print(f"å¤„ç†Wordè¡¨æ ¼ {table_idx + 1}")
        for row_idx, row in enumerate(table.rows):
            cells = [cell.text.strip() for cell in row.cells]
            if len(cells) >= 4:
                # è·³è¿‡è¡¨å¤´
                if cells[0] and not cells[0].startswith(('åºå·', 'æ’å', 'å§“å')):
                    student_id = cells[0]
                    grade = cells[3] if len(cells) > 3 else ""
                    
                    data.append({
                        'å­¦å·': student_id,
                        'æ™ºè‚²æˆç»©': grade,
                        'è¡¨æ ¼': table_idx + 1,
                        'è¡Œ': row_idx + 1
                    })
    
    # å¦‚æœæ²¡æœ‰è¡¨æ ¼æˆ–è¡¨æ ¼ä¸ºç©ºï¼Œå°è¯•ä»æ®µè½ä¸­æå–
    if not data:
        for para_idx, paragraph in enumerate(doc.paragraphs):
            text = paragraph.text.strip()
            if text:
                import re
                parts = re.split(r'\s+', text)
                if len(parts) >= 4 and parts[0].isdigit():
                    data.append({
                        'å­¦å·': parts[0],
                        'æ™ºè‚²æˆç»©': parts[3],
                        'æ®µè½': para_idx + 1
                    })
    
    print(f"ä»Wordæå–äº† {len(data)} æ¡è®°å½•")
    return data

def compare_data(pdf_data, word_data):
    """æ¯”å¯¹PDFå’ŒWordæ•°æ®"""
    print("\nå¼€å§‹æ¯”å¯¹æ•°æ®...")
    
    # è½¬æ¢ä¸ºDataFrameä¾¿äºæ¯”è¾ƒ
    pdf_df = pd.DataFrame(pdf_data)
    word_df = pd.DataFrame(word_data)
    
    print(f"PDFæ•°æ®è¡Œæ•°: {len(pdf_df)}")
    print(f"Wordæ•°æ®è¡Œæ•°: {len(word_df)}")
    
    if len(pdf_df) == 0:
        print("âŒ PDFæ•°æ®ä¸ºç©º!")
        return False
    
    if len(word_df) == 0:
        print("âŒ Wordæ•°æ®ä¸ºç©º!")
        return False
    
    # æŒ‰å­¦å·æ’åº
    pdf_df = pdf_df.sort_values('å­¦å·').reset_index(drop=True)
    word_df = word_df.sort_values('å­¦å·').reset_index(drop=True)
    
    # æ‰¾å‡ºä¸åŒ¹é…çš„è®°å½•
    mismatches = []
    all_student_ids = set(pdf_df['å­¦å·'].tolist() + word_df['å­¦å·'].tolist())
    
    for student_id in sorted(all_student_ids):
        pdf_row = pdf_df[pdf_df['å­¦å·'] == student_id]
        word_row = word_df[word_df['å­¦å·'] == student_id]
        
        if pdf_row.empty:
            mismatches.append(f"å­¦å· {student_id}: åœ¨PDFä¸­æœªæ‰¾åˆ°")
        elif word_row.empty:
            mismatches.append(f"å­¦å· {student_id}: åœ¨Wordä¸­æœªæ‰¾åˆ°")
        else:
            pdf_grade = pdf_row.iloc[0]['æ™ºè‚²æˆç»©']
            word_grade = word_row.iloc[0]['æ™ºè‚²æˆç»©']
            
            if str(pdf_grade) != str(word_grade):
                mismatches.append(f"å­¦å· {student_id}: æ™ºè‚²æˆç»©ä¸åŒ¹é… (PDF: {pdf_grade}, Word: {word_grade})")
    
    # è¾“å‡ºç»“æœ
    if not mismatches:
        print("âœ… æ‰€æœ‰æ•°æ®å®Œå…¨ä¸€è‡´!")
        print(f"å…±æ¯”å¯¹äº† {len(all_student_ids)} ä¸ªå­¦ç”Ÿçš„è®°å½•")
        return True
    else:
        print(f"âŒ å‘ç° {len(mismatches)} å¤„ä¸åŒ¹é…:")
        for mismatch in mismatches[:20]:  # åªæ˜¾ç¤ºå‰20ä¸ªä¸åŒ¹é…é¡¹
            print(f"  - {mismatch}")
        
        if len(mismatches) > 20:
            print(f"  ... è¿˜æœ‰ {len(mismatches) - 20} ä¸ªä¸åŒ¹é…é¡¹")
        
        return False

def main():
    """ä¸»å‡½æ•°"""
    current_dir = Path(__file__).parent
    
    pdf_file = current_dir / "è®¡ç®—æœºå­¦é™¢ï¼ˆå›½å®¶ç¤ºèŒƒæ€§è½¯ä»¶å­¦é™¢ï¼‰æœ¬ç§‘2023çº§è®¡ç®—æœºç±»2023-2024å­¦å¹´ç»¼åˆæˆç»©å…¬ç¤º.pdf"
    word_file = current_dir / "è®¡ç®—æœºå­¦é™¢ï¼ˆå›½å®¶ç¤ºèŒƒæ€§è½¯ä»¶å­¦é™¢ï¼‰æœ¬ç§‘2023çº§è®¡ç®—æœºç±»2023-2024å­¦å¹´ç»¼åˆæˆç»©å…¬ç¤º.docx"
    
    if not pdf_file.exists():
        print(f"âŒ PDFæ–‡ä»¶ä¸å­˜åœ¨: {pdf_file}")
        return
    
    if not word_file.exists():
        print(f"âŒ Wordæ–‡ä»¶ä¸å­˜åœ¨: {word_file}")
        return
    
    try:
        # æå–æ•°æ®
        pdf_data = extract_pdf_data(pdf_file)
        word_data = extract_word_data(word_file)
        
        # æ¯”å¯¹æ•°æ®
        is_match = compare_data(pdf_data, word_data)
        
        # ä¿å­˜è¯¦ç»†æ¯”å¯¹ç»“æœåˆ°æ–‡ä»¶
        if pdf_data and word_data:
            pdf_df = pd.DataFrame(pdf_data)
            word_df = pd.DataFrame(word_data)
            
            # ä¿å­˜æå–çš„æ•°æ®
            pdf_df.to_csv(current_dir / "pdf_extracted_data.csv", index=False, encoding='utf-8-sig')
            word_df.to_csv(current_dir / "word_extracted_data.csv", index=False, encoding='utf-8-sig')
            print(f"\nğŸ“Š è¯¦ç»†æ•°æ®å·²ä¿å­˜åˆ°:")
            print(f"  - pdf_extracted_data.csv")
            print(f"  - word_extracted_data.csv")
        
        if is_match:
            print("\nğŸ‰ éªŒè¯å®Œæˆ: PDFå’ŒWordæ–‡æ¡£æ•°æ®å®Œå…¨ä¸€è‡´!")
        else:
            print("\nâš ï¸  éªŒè¯å®Œæˆ: å‘ç°æ•°æ®ä¸ä¸€è‡´ï¼Œè¯·æŸ¥çœ‹ä¸Šé¢çš„è¯¦ç»†ä¿¡æ¯")
            
    except Exception as e:
        print(f"âŒ å‘ç”Ÿé”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
